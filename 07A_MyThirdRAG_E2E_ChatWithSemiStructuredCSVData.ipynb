{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDe7DsPWmEBV"
      },
      "source": [
        "# AIChampionsHub : Academy\n",
        "\n",
        "### Module 2: Adapting AI for Enterprise Use : Retrival Augmented Generation\n",
        "\n",
        "### Use Case 07 : Using Semi-Structured Data for \"Chat with Data\" Use\n",
        "This is part of Course by **AIChampionsHub** - AI Fundamentals and AI Engineering Courses leverage this Notebook.\n",
        "\n",
        "---\n",
        "<a href=\"https://github.com/aichampionslearn/01_LLM_Basics\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/aichampionslearn/01_LLM_Basics/blob/main/AICH_L2_AIAgents_M1_D3_BasicLLMAppv01.ipynb)"
      ],
      "id": "EDe7DsPWmEBV"
    },
    {
      "cell_type": "markdown",
      "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
      "metadata": {
        "id": "ef597741-3211-4ecc-92f7-f58023ee237e"
      },
      "source": [
        "### Objective\n",
        "\n",
        "- AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of activity. Here is a link to Kaggle site:\n",
        "https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset\n",
        "\n",
        "- We will this semi-structured data, store in Vector Database, Apply Embeddings and use to enable user Analysis\n",
        "\n",
        "For OpenAI please make sure that you a `OPENAI_API_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture --no-stderr\n",
        "!pip install wget --quiet\n",
        "!pip install pandas --quiet\n",
        "!pip install chromadb --quiet"
      ],
      "metadata": {
        "id": "G4XT4ztYFRd1"
      },
      "id": "G4XT4ztYFRd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9a52c8",
      "metadata": {
        "id": "0f9a52c8"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet -U langchain_openai langchain_core langchain_community langchain_ollama langchain_chroma tavily-python\n",
        "!pip install --quiet sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_ollama import OllamaEmbeddings\n",
        "# from langchain_community.vectorstores import Chroma\n",
        "\n",
        "import os, getpass\n",
        "from google.colab import userdata   #For Secret Key\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.schema import Document\n",
        "from tqdm import tqdm  # For showing Progress bar during longer iterations\n",
        "\n",
        "import wget                         # To download data file from OpenAI Site\n",
        "import  pandas as pd                # DataFrame for easy data manipulation"
      ],
      "metadata": {
        "id": "jExBI4qlEyG1"
      },
      "id": "jExBI4qlEyG1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a15227",
      "metadata": {
        "id": "c2a15227"
      },
      "outputs": [],
      "source": [
        "def _set_OpenAIKey(var: str, env:int):\n",
        "    if not env:\n",
        "        key = userdata.get(var)\n",
        "        os.environ[var] = key\n",
        "    else:\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "    return key;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = _set_OpenAIKey(\"OPENAI_API_KEY\",0) #0 for reading from userdata"
      ],
      "metadata": {
        "id": "SBO_eJMHdu-W"
      },
      "id": "SBO_eJMHdu-W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA_FILE_PATH_URL = \"https://github.com/openai/openai-cookbook/blob/main/examples/data/AG_news_samples.csv\"\n",
        "DATA_FILE_PATH_URL = \"https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/data/AG_news_samples.csv\"\n",
        "DATA_FILE_NAME = \"AG_news_samples.csv\""
      ],
      "metadata": {
        "id": "Thn039LREKR9"
      },
      "id": "Thn039LREKR9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(DATA_FILE_NAME):\n",
        "    wget.download(DATA_FILE_PATH_URL, DATA_FILE_NAME)\n",
        "    print('File downloaded successfully.')\n",
        "else:\n",
        "    print('File already exists in the local file system.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUklX7x3EnME",
        "outputId": "035e6e14-7393-468d-c20d-9643887ea4a5"
      },
      "id": "VUklX7x3EnME",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Embedding Model"
      ],
      "metadata": {
        "id": "l0Zhg32fOS7r"
      },
      "id": "l0Zhg32fOS7r"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/\" + DATA_FILE_NAME)\n",
        "# data = df.to_dict(orient='records')  #List of Dictionary values - name:value pairs\n",
        "# data[0:2]\n",
        "df = df[0:20].copy()"
      ],
      "metadata": {
        "id": "kdAlrDU4G7v_"
      },
      "id": "kdAlrDU4G7v_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --quiet sentence-transformers"
      ],
      "metadata": {
        "id": "c13cKPWBo-ES"
      },
      "id": "c13cKPWBo-ES",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
        "\n",
        "# Below is a a smaller model if you want to use\n",
        "# all-MiniLM-L6-v2\n",
        "# embedding_model = SentenceTransformer('flax-sentence-embeddings/all_datasets_v3_mpnet-base')\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2' # \"text-embedding-3-large\"\n",
        "EMBEDDING_MODEL_NAME = \"text-embedding-3-small\"  # Use a valid OpenAI embedding model name\n",
        "embedding_model = OpenAIEmbeddings(model=EMBEDDING_MODEL_NAME)"
      ],
      "metadata": {
        "id": "podjhlLWDGFh"
      },
      "id": "podjhlLWDGFh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP3 : Setup a Database (vector) to Store our Data"
      ],
      "metadata": {
        "id": "7CDkUbsSHgLN"
      },
      "id": "7CDkUbsSHgLN"
    },
    {
      "cell_type": "code",
      "source": [
        "COLLECTION_NAME = \"AG_news\"\n",
        "# collection = client.create_collection(name=\"ag_news\")\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "vector_db = Chroma(\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
        ")"
      ],
      "metadata": {
        "id": "zrJZOJj9fjL-"
      },
      "id": "zrJZOJj9fjL-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "IWdTRS2YoJPB"
      },
      "id": "IWdTRS2YoJPB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fn_embed_with_chroma_v01(df, embedding_model):\n",
        "    documents_to_add = []\n",
        "\n",
        "    # Process each row in the DataFrame with a progress bar\n",
        "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "\n",
        "        description = row['description']\n",
        "        embedding = embedding_model.embed_documents(description)\n",
        "        print(description)\n",
        "        print(embedding[0:20])\n",
        "        document = Document(\n",
        "            page_content = description, # Text Content for Embedding\n",
        "            metadata={'title': row['title'], 'label': row['label']},\n",
        "            id = str(index),\n",
        "            embedding = embedding\n",
        "        )\n",
        "        # embedding = embedding_model.embed_documents([document.page_content])[0]\n",
        "\n",
        "        # Append the document directly to documents_to_add\n",
        "        documents_to_add.append(document)\n",
        "\n",
        "    # Add documents to the vector store using add_documents outside the loop\n",
        "    vector_db.add_documents(documents=documents_to_add)\n",
        "\n",
        "    return vector_db;"
      ],
      "metadata": {
        "id": "DC0J4NY1sH0B"
      },
      "id": "DC0J4NY1sH0B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fn_embed_with_chroma(df, embedding_model):\n",
        "    embeddings = []\n",
        "    documents_to_add = []\n",
        "\n",
        "    # Process each row in the DataFrame with a progress bar\n",
        "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "\n",
        "        document = Document(\n",
        "            page_content = row['description'], # Text Content for Embedding\n",
        "            metadata={'title': row['title'], 'label': row['label']},\n",
        "            id = str(index)\n",
        "        )\n",
        "        # embedding = embedding_model.embed_documents([document.page_content])[0]\n",
        "        embedding = embedding_model.embed_documents([document.page_content])[0]\n",
        "        embeddings.append((document, embedding))\n",
        "\n",
        "        documents_to_add.append(embeddings)\n",
        "    # Add documents to the vector store using add_documents\n",
        "\n",
        "    vector_db.add_documents(documents=documents_to_add)\n",
        "\n",
        "    return embeddings;"
      ],
      "metadata": {
        "id": "9ucaFMlyhaPr"
      },
      "id": "9ucaFMlyhaPr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# document_embeddings  = fn_embed_with_chroma(df, embedding_model)\n",
        "fn_embed_with_chroma_v01(df, embedding_model)"
      ],
      "metadata": {
        "id": "0AM8nodchji8"
      },
      "id": "0AM8nodchji8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for documents similar to the query \"climate change\" and get top 3 results:\n",
        "QUERY = \"climate change\"\n",
        "results = vector_db.similarity_search(QUERY, k=3)\n",
        "\n",
        "# Print the page content of the most similar document:\n",
        "print(results[0].page_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLQDrEuEvmsn",
        "outputId": "07899f33-d4b4-447e-81cf-5d2fcbd2ef8d"
      },
      "id": "OLQDrEuEvmsn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BRITAIN: BLAIR WARNS OF CLIMATE THREAT Prime Minister Tony Blair urged the international community to consider global warming a dire threat and agree on a plan of action to curb the  quot;alarming quot; growth of greenhouse gases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for documents similar to the query \"climate change\" and get top 3 results:\n",
        "QUERY = \"Technology Trends\"\n",
        "results = vector_db.similarity_search(QUERY, k=3)\n",
        "\n",
        "# Print the page content of the most similar document:\n",
        "print(results[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3PVnNnYv8A2",
        "outputId": "147126d6-98ce-42fe-e77b-c77a0cbefa77"
      },
      "id": "q3PVnNnYv8A2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Any product, any shape, any size -- manufactured on your desktop! The future is the fabricator. By Bruce Sterling from Wired magazine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for documents similar to the query \"climate change\" and get top 3 results:\n",
        "QUERY = \"Articles about India\"\n",
        "results = vector_db.similarity_search(QUERY, k=3)\n",
        "\n",
        "# Print the page content of the most similar document:\n",
        "print(results[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31YMQqpVwLBv",
        "outputId": "92cb14b8-3e34-47c1-f429-b7c21d62ba4b"
      },
      "id": "31YMQqpVwLBv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AFP - Hosts India braced themselves for a harrowing chase on a wearing wicket in the first Test after Australia declined to enforce the follow-on here.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}